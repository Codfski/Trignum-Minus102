{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Curvature Bifurcation in Self-Consistent Neural Loss Landscapes\n",
    "\n",
    "Authors: Moez Abdessattar, Antigravity AI Cohort  \n",
    "Date: February 27, 2026  \n",
    "Notebook: Complete Analysis & Reproducible Experiments\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Overview\n",
    "\n",
    "This notebook contains the complete numerical analysis for the paper:\n",
    "\n",
    "> \"Curvature Bifurcation Induced by Self-Consistency Coupling in Neural Loss Landscapes\"\n",
    "\n",
    "We investigate what happens when neural networks try to model themselves through a self-consistency loss:\n",
    "\n",
    "$$L(\\theta) = L_{\\text{task}}(\\theta) + \\alpha \\| f_\\theta(\\theta) - \\theta \\|^2$$\n",
    "\n",
    "### üî¨ Key Findings\n",
    "\n",
    "1. The Hessian of the self-consistency term decomposes into:\n",
    "   - A positive semidefinite linear part: $(J-I)^T(J-I)$\n",
    "   - An indefinite nonlinear part: $\\sum_i r_i \\nabla^2 f_i$\n",
    "\n",
    "2. At a critical weight $\\alpha_c$, the minimum eigenvalue of the total Hessian crosses zero\n",
    "\n",
    "3. This bifurcation is reproducible across dimensions ($n=50-200$) and random initializations\n",
    "\n",
    "4. $\\alpha_c = 1.85 \\pm 0.11$ under our experimental conditions\n",
    "\n",
    "### üß™ The -102 Story\n",
    "\n",
    "This investigation began with an intriguing numerical observation: under certain heuristic scaling, the bifurcation appeared near a fixed value of -102. Systematic analysis revealed this was an artifact of scaling choices. The journey from illusory constant to rigorous theory is documented in Section 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create figures directory\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Core Mathematical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from curvature_model import f, J, H_f, S, create_task_hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Experiment 1: Curvature Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from experiments import run_transition\n",
    "alpha_c = run_transition(n=50, n_trials=20, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Experiment 2: Distribution of Œ±_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from experiments import run_histogram\n",
    "run_histogram(n=50, n_trials=20, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ The -102 Illusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from experiments import run_illusion\n",
    "run_illusion(n=50, n_trials=10, savefig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary of Results\n",
    "\n",
    "The numerical evidence confirms that adding a self-consistency weight $\\alpha$ beyond a critical threshold $\\alpha_c \\approx 1.85$ induces a curvature bifurcation, where the loss landscape develops negative eigenvalues (saddle points). This reveals a fundamental stability limit for self-referential neural systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
